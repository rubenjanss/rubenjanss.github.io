---
layout: post
title: Audiovisual Learning
description: Why realistic lip movements might not make social robots better for language learning 
---

If you want to know more about this research, [read our paper](https://dl.acm.org/doi/10.1145/3568162.3578633), which was presented at the 2023 Human-Robot Interaction conference! You can also watch our [presentation](https://www.youtube.com/watch?v=pWMPBNGwmMY) just below.

<iframe width="560" height="315" src="https://www.youtube.com/embed/pWMPBNGwmMY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

Feel free to get in touch if you have any other questions or want to know more! You can use any of the channels at the bottom of this page, or send an email to ruben[dot]janssens[at]ugent[dot]be.

If you use our work in any future research, please use the following citation:

~~~~
@inproceedings{10.1145/3568162.3578633,
author = {Amioka, Saya and Janssens, Ruben and Wolfert, Pieter and Ren, Qiaoqiao and Pinto Bernal, Maria Jose and Belpaeme, Tony},
title = {Limitations of Audiovisual Speech on Robots for Second Language Pronunciation Learning},
year = {2023},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3568162.3578633},
doi = {10.1145/3568162.3578633},
booktitle = {Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {359â€“367},
series = {HRI '23}
}
~~~~
